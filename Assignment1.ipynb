{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt \n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading():\n",
    "    #load data from 19 participants\n",
    "     for i in range(19):\n",
    "        df = pd.read_csv('dataset/dataset_' + str(i + 1) + '.txt', sep=',', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_visulization():\n",
    "    # read dataset file\n",
    "    for i in range(1,14):\n",
    "        df_activities = df[df[24] == i].values\n",
    "        plt.plot(df_activities[:5000,18:21])\n",
    "        plt.plot(df_activities[:5000,22:25])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_removing():\n",
    "    #Butterworth Low-pass\n",
    "    b, a = signal.butter(4, 0.04, 'low', analog = False)\n",
    "    for c in range(1, 14):\n",
    "        activity_data = df[df[24] == c].values\n",
    "        for j in range(24):\n",
    "            activity_data[:, j] = signal.lfilter(b, a, activity_data[:, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering():\n",
    "    training = np.empty(shape=(0, 22))\n",
    "    testing = np.empty(shape=(0, 22))\n",
    "    # deal with each dataset file\n",
    "    for i in range(19):\n",
    "        df = pd.read_csv('dataset/dataset_' + str(i + 1) + '.txt', sep=',', header=None)\n",
    "        print('deal with dataset ' + str(i + 1))\n",
    "        for c in range(1, 14):\n",
    "            activity_data = df[df[24] == c].values\n",
    "            b, a = signal.butter(4, 0.04, 'low', analog=False)\n",
    "            for j in range(24):\n",
    "                activity_data[:, j] = signal.lfilter(b, a, activity_data[:, j])\n",
    "            \n",
    "            datat_len = len(activity_data)\n",
    "            training_len = math.floor(datat_len * 0.8)\n",
    "            training_data = activity_data[:training_len, :]\n",
    "            testing_data = activity_data[training_len:, :]\n",
    "\n",
    "            training_sample_number = training_len // 1000 + 1\n",
    "            testing_sample_number = (datat_len - training_len) // 1000 + 1\n",
    "\n",
    "            for s in range(training_sample_number):\n",
    "                if s < training_sample_number - 1:\n",
    "                    sample_data = training_data[1000*s:1000*(s + 1), :]\n",
    "                else:\n",
    "                    sample_data = training_data[1000*s:, :]\n",
    "                feature_sample = []\n",
    "                for i in range(18,25):\n",
    "                    feature_sample.append(np.min(sample_data[:, i]))\n",
    "                    feature_sample.append(np.max(sample_data[:, i]))\n",
    "                    feature_sample.append(np.mean(sample_data[:, i]))\n",
    "                feature_sample.append(sample_data[0, -1])\n",
    "                feature_sample = np.array([feature_sample])\n",
    "                training = np.concatenate((training, feature_sample), axis=0)\n",
    "            \n",
    "            for s in range(testing_sample_number):\n",
    "                if s < training_sample_number - 1:\n",
    "                    sample_data = testing_data[1000*s:1000*(s + 1), :]\n",
    "                else:\n",
    "                    sample_data = testing_data[1000*s:, :]\n",
    "\n",
    "                feature_sample = []\n",
    "                for i in range(18,25):\n",
    "                    feature_sample.append(np.min(sample_data[:, i]))\n",
    "                    feature_sample.append(np.max(sample_data[:, i]))\n",
    "                    feature_sample.append(np.mean(sample_data[:, i]))\n",
    "                feature_sample.append(sample_data[0, -1])\n",
    "                feature_sample = np.array([feature_sample])\n",
    "                testing = np.concatenate((testing, feature_sample), axis=0)\n",
    "\n",
    "    df_training = pd.DataFrame(training)\n",
    "    df_testing = pd.DataFrame(testing)\n",
    "    df_training.to_csv('training_data.csv', index=None, header=None)\n",
    "    df_testing.to_csv('testing_data.csv', index=None, header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training_and_evaluation_example():\n",
    "    df_training = pd.read_csv('training_data.csv', header=None)\n",
    "    df_testing = pd.read_csv('testing_data.csv', header=None)\n",
    "\n",
    "    y_train = df_training[19].values\n",
    "    y_train = y_train - 1\n",
    "    df_training = df_training.drop([19], axis=1)\n",
    "    X_train = df_training.values\n",
    "\n",
    "    y_test = df_testing[19].values\n",
    "    y_test = y_test - 1\n",
    "    df_testing = df_testing.drop([19], axis=1)\n",
    "    X_test = df_testing.values\n",
    "    # StandardScaler for data normalization\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Build KNN classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "    # confusion matrix\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    #SVM classifier\n",
    "    tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-1,1e-2, 1e-3, 1e-4],\n",
    "                     'C': [1e-3, 1e-2, 1e-1, 1, 10, 100, 100]},\n",
    "                    {'kernel': ['linear'], 'C': [1e-3, 1e-2, 1e-1, 1, 10, 100]}]\n",
    "    acc_scorer = make_scorer(accuracy_score)\n",
    "    grid_obj  = GridSearchCV(SVC(), tuned_parameters, cv=10, scoring=acc_scorer)\n",
    "    grid_obj  = grid_obj .fit(X_train, y_train)\n",
    "    clf = grid_obj.best_estimator_\n",
    "    print('best clf:', clf)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9328214971209213\n",
      "[[ 57   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0  57   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0  57   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0  96   2   1   0   0   0   0   0   0   0]\n",
      " [  0   0   1   5  30  21   0   0   0   0   0   0   0]\n",
      " [  0   0   0   2  16  65   0   2   0   0   0   0   0]\n",
      " [  0   0   0   0   1   7 211   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   1   1  37   0   0   0   0   0]\n",
      " [  0   0   0   0   0   1   1   0  36   0   0   0   0]\n",
      " [  0   0   0   0   0   0   1   0   0  95   0   0   0]\n",
      " [  0   0   0   0   0   0   1   0   1   0  98   0   0]\n",
      " [  0   0   0   0   0   0   2   0   0   0   0  98   0]\n",
      " [  0   0   0   0   0   0   2   0   0   0   0   1  35]]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "   # feature_engineering()\n",
    "    model_training_and_evaluation_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
